{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(ggExtra)\n",
    "library(brms)\n",
    "library(reshape2)\n",
    "library(coda)\n",
    "library(tidybayes)\n",
    "library(ggstance)\n",
    "library(viridis)\n",
    "library(latex2exp)\n",
    "library(ggthemes)\n",
    "library(data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data <- function(){\n",
    "    filename <- \"C:/Users/Arkady/Google Drive/data/beyond_the_reach/k-values.txt\"\n",
    "    data <- read.table(filename, header = TRUE, sep = \"\\t\")\n",
    "    data[, 'subj_id'] <- factor(data[, 'subj_id'])  \n",
    "    data[, 'task'] <- factor(data[, 'task'])  \n",
    "    data[, 'order'] <- factor(data[, 'order'])  \n",
    "    return(data)\n",
    "}\n",
    "\n",
    "data <- get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bf_k <- function(data){\n",
    "    # sd(IV) in this case is 0.5, as IV is task (equal number of 0's and 1's)\n",
    "    priors_task <- c(set_prior(sprintf('normal(%f, %f)', mean(data$k), sd(data$k)), class = 'Intercept'),\n",
    "                    set_prior(sprintf('cauchy(0.0, %f)', 0.707*sd(data$k)/0.5), class = 'b'))\n",
    "\n",
    "    m_null <- brm(k ~ (1 | subj_id), data=data, family=gaussian(), save_all_pars=TRUE, prior=priors_task[1,],\n",
    "                  refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "    m_task <- brm(k ~ (1 | subj_id) + task, data=data, family=gaussian(), save_all_pars=TRUE, prior=priors_task, \n",
    "                  refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))    \n",
    "    m_order <- brm(k ~ (1 | subj_id) + order, data=data, family=gaussian(), save_all_pars=TRUE, prior=priors_task, \n",
    "                  refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "#     m_inter <- brm(k ~ (1 | subj_id) + task*order, data=data, family=gaussian(), save_all_pars=TRUE, prior=priors_task, \n",
    "#                   refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "    \n",
    "    bf_task <- bayes_factor(x1=m_task, x2=m_null)$bf\n",
    "    bf_order <- bayes_factor(x1=m_order, x2=m_null)$bf\n",
    "#     bf_inter <- bayes_factor(x1=m_inter, x2=m_null)$bf\n",
    "    names(bf_task) <- 'bf_task'\n",
    "    names(bf_order) <- 'bf_order'\n",
    "#     names(bf_inter) <- 'bf_inter'\n",
    "        \n",
    "    result = list(bf=t(c(bf_task, bf_order)), m_null=m_null, m_task=m_task)\n",
    "    \n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.316 seconds (Warm-up)\n",
      "               0.156 seconds (Sampling)\n",
      "               0.472 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.292 seconds (Warm-up)\n",
      "               0.161 seconds (Sampling)\n",
      "               0.453 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.283 seconds (Warm-up)\n",
      "               0.152 seconds (Sampling)\n",
      "               0.435 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.324 seconds (Warm-up)\n",
      "               0.141 seconds (Sampling)\n",
      "               0.465 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.384 seconds (Warm-up)\n",
      "               0.193 seconds (Sampling)\n",
      "               0.577 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.365 seconds (Warm-up)\n",
      "               0.162 seconds (Sampling)\n",
      "               0.527 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.352 seconds (Warm-up)\n",
      "               0.153 seconds (Sampling)\n",
      "               0.505 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.344 seconds (Warm-up)\n",
      "               0.168 seconds (Sampling)\n",
      "               0.512 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.432 seconds (Warm-up)\n",
      "               0.198 seconds (Sampling)\n",
      "               0.63 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.396 seconds (Warm-up)\n",
      "               0.19 seconds (Sampling)\n",
      "               0.586 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.377 seconds (Warm-up)\n",
      "               0.247 seconds (Sampling)\n",
      "               0.624 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.373 seconds (Warm-up)\n",
      "               0.181 seconds (Sampling)\n",
      "               0.554 seconds (Total)\n",
      "\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n"
     ]
    }
   ],
   "source": [
    "result <- get_bf_k(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>bf_task</th><th scope=col>bf_order</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.101266 </td><td>0.1692236</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " bf\\_task & bf\\_order\\\\\n",
       "\\hline\n",
       "\t 0.101266  & 0.1692236\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "bf_task | bf_order | \n",
       "|---|\n",
       "| 0.101266  | 0.1692236 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     bf_task  bf_order \n",
       "[1,] 0.101266 0.1692236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result$bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd<-HPDinterval(as.mcmc(result$m_task, combine_chains = TRUE))['b_taskwalking',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>lower</dt>\n",
       "\t\t<dd>-0.0699762433130167</dd>\n",
       "\t<dt>upper</dt>\n",
       "\t\t<dd>0.0252735393029451</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[lower] -0.0699762433130167\n",
       "\\item[upper] 0.0252735393029451\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "lower\n",
       ":   -0.0699762433130167upper\n",
       ":   0.0252735393029451\n",
       "\n"
      ],
      "text/plain": [
       "      lower       upper \n",
       "-0.06997624  0.02527354 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hpd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
