{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(ggExtra)\n",
    "library(brms)\n",
    "library(reshape2)\n",
    "library(coda)\n",
    "library(tidybayes)\n",
    "library(ggstance)\n",
    "library(viridis)\n",
    "library(latex2exp)\n",
    "library(ggthemes)\n",
    "library(data.table)\n",
    "library(bayesplot)\n",
    "library(fitdistrplus)\n",
    "library(bda)\n",
    "library(arules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path <- \"C:/Users/Arkady/Google Drive/data/beyond_the_reach\"\n",
    "table_path <- \"C:/Users/Arkady/Dropbox/Research/Journal papers/2018 Beyond the reach/tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_data <- function(data_path, file_name){\n",
    "    data <- read.table(file.path(data_path, file_name), header = TRUE, sep = \"\\t\")\n",
    "    data[, 'subj_id'] <- factor(data[, 'subj_id'])  \n",
    "    data[, 'task'] <- factor(data[, 'task'])  \n",
    "    data[, 'session'] <- factor(data[, 'session'])  \n",
    "    data$AUC <- 1 - data$k\n",
    "\n",
    "    return(data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bf_k <- function(data, var, family, rscale, n=1){\n",
    "    bfs <- data.frame(double(), double(), double())\n",
    "    \n",
    "    for (i in 1:n) {\n",
    "        # sd(var) in this case is 0.5, as var is task (equal number of 0's and 1's)\n",
    "        priors_task <- c(set_prior(sprintf('normal(%f, %f)', mean(data[, var]), sd(data[, var])), class='Intercept'),\n",
    "                        set_prior(sprintf('cauchy(0.0, %f)', rscale*sd(data[, var])/0.5), class='b'))\n",
    "\n",
    "        formula_null <- as.formula(paste(var, \"~ (1 | subj_id)\"))\n",
    "        formula_task <- as.formula(paste(var, \"~ (1 | subj_id) + task\"))\n",
    "        formula_session <- as.formula(paste(var, \"~ (1 | subj_id) + session\"))\n",
    "        formula_inter <- as.formula(paste(var, \"~ (1 | subj_id) + task*session\"))\n",
    "\n",
    "        m_null <- brm(formula_null, data=data, family=family, save_all_pars=TRUE, prior=priors_task[1,],\n",
    "                      refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "        m_task <- brm(formula_task, data=data, family=family, save_all_pars=TRUE, prior=priors_task, \n",
    "                      refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))    \n",
    "        m_session <- brm(formula_session, data=data, family=family, save_all_pars=TRUE, prior=priors_task, \n",
    "                      refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "        m_inter <- brm(formula_inter, data=data, family=family, save_all_pars=TRUE, prior=priors_task, \n",
    "                      refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "        \n",
    "        bf <- t(c(bayes_factor(x1=m_task, x2=m_null)$bf, \n",
    "                  bayes_factor(x1=m_session, x2=m_null)$bf, \n",
    "                  bayes_factor(x1=m_inter, x2=m_null)$bf))\n",
    "#         bf_task <- bayes_factor(x1=m_task, x2=m_null)$bf\n",
    "#         bf_session <- bayes_factor(x1=m_session, x2=m_null)$bf\n",
    "#         bf_inter <- bayes_factor(x1=m_inter, x2=m_null)$bf\n",
    "\n",
    "#         names(bf_task) <- 'bf_task'\n",
    "#         names(bf_session) <- 'bf_session'\n",
    "#         names(bf_inter) <- 'bf_inter'\n",
    "        bfs <- rbind(bfs, bf)\n",
    "    }\n",
    "    \n",
    "    colnames(bfs) <- c('bf_task', 'bf_session', 'bf_inter')\n",
    "    \n",
    "    # to visualize posteriors, we just use the model fitted last\n",
    "    result = list(bf=colMeans(bfs),  \n",
    "                  m_null=m_null, \n",
    "                  m_task=m_task, \n",
    "                  m_session=m_session,\n",
    "                  m_inter=m_inter)\n",
    "    \n",
    "    return(result)\n",
    "}\n",
    "\n",
    "save_posterior <- function(model, file_name){    \n",
    "    write.csv(as.matrix(as.mcmc(model, combine_chains=TRUE)), \n",
    "              file=file.path(\"posterior_csv\", file_name), row.names=FALSE)\n",
    "}\n",
    "\n",
    "show_result <- function(result) {\n",
    "    print(\"Bayes factors: \")\n",
    "    print(result$bf)\n",
    "    hpd_task<-HPDinterval(as.mcmc(result$m_task, combine_chains = TRUE))\n",
    "    hpd_session<-HPDinterval(as.mcmc(result$m_session, combine_chains = TRUE))\n",
    "    print(\"Credible interval for the task effect (walking relative to mouse): \")\n",
    "    print(hpd_task['b_taskwalking',])\n",
    "    print(\"Credible interval for the session effect (2nd session relative to 1st): \")\n",
    "    print(hpd_session['b_sessionsecond',])\n",
    "#     mcmc_areas_ridges(as.matrix(as.mcmc(result$m_bias, combine_chains = TRUE)), regex_pars = \"b_task\", prob=0.95)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preregistered analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 108\n"
     ]
    }
   ],
   "source": [
    "data <- get_data(data_path, \"k_values_54.csv\")\n",
    "print(nrow(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>subj_id</th><th scope=col>task</th><th scope=col>k</th><th scope=col>session</th><th scope=col>sequence</th><th scope=col>SS_bias</th><th scope=col>AUC</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1322       </td><td>mouse      </td><td>0.9325057  </td><td>first      </td><td>mw         </td><td>-0.48821750</td><td>0.06749429 </td></tr>\n",
       "\t<tr><td>1402       </td><td>mouse      </td><td>0.9703482  </td><td>first      </td><td>mw         </td><td> 0.03046794</td><td>0.02965183 </td></tr>\n",
       "\t<tr><td>1408       </td><td>mouse      </td><td>0.3983733  </td><td>second     </td><td>wm         </td><td> 0.11081885</td><td>0.60162671 </td></tr>\n",
       "\t<tr><td>1474       </td><td>mouse      </td><td>0.8751284  </td><td>first      </td><td>mw         </td><td>-0.04696042</td><td>0.12487158 </td></tr>\n",
       "\t<tr><td>1879       </td><td>mouse      </td><td>0.8239869  </td><td>second     </td><td>wm         </td><td>-0.27269836</td><td>0.17601313 </td></tr>\n",
       "\t<tr><td>2045       </td><td>mouse      </td><td>0.7232734  </td><td>first      </td><td>mw         </td><td>-0.50074000</td><td>0.27672660 </td></tr>\n",
       "\t<tr><td>2249       </td><td>mouse      </td><td>0.9584760  </td><td>first      </td><td>mw         </td><td>-0.60422898</td><td>0.04152397 </td></tr>\n",
       "\t<tr><td>2261       </td><td>mouse      </td><td>0.8941924  </td><td>first      </td><td>mw         </td><td>-0.57138308</td><td>0.10580765 </td></tr>\n",
       "\t<tr><td>2752       </td><td>mouse      </td><td>0.9527112  </td><td>second     </td><td>wm         </td><td> 0.14741077</td><td>0.04728881 </td></tr>\n",
       "\t<tr><td>2758       </td><td>mouse      </td><td>0.8964184  </td><td>second     </td><td>wm         </td><td>-0.17682609</td><td>0.10358162 </td></tr>\n",
       "\t<tr><td>3713       </td><td>mouse      </td><td>0.9201627  </td><td>first      </td><td>mw         </td><td>-0.24616666</td><td>0.07983733 </td></tr>\n",
       "\t<tr><td>3720       </td><td>mouse      </td><td>0.9576056  </td><td>first      </td><td>mw         </td><td>-0.11799166</td><td>0.04239441 </td></tr>\n",
       "\t<tr><td>4037       </td><td>mouse      </td><td>0.2347175  </td><td>second     </td><td>wm         </td><td>-0.17281631</td><td>0.76528253 </td></tr>\n",
       "\t<tr><td>4413       </td><td>mouse      </td><td>0.8990725  </td><td>first      </td><td>mw         </td><td> 0.10286513</td><td>0.10092751 </td></tr>\n",
       "\t<tr><td>4422       </td><td>mouse      </td><td>0.9084047  </td><td>first      </td><td>mw         </td><td>-0.16070781</td><td>0.09159532 </td></tr>\n",
       "\t<tr><td>4441       </td><td>mouse      </td><td>0.8923516  </td><td>second     </td><td>wm         </td><td> 0.14034046</td><td>0.10764840 </td></tr>\n",
       "\t<tr><td>5181       </td><td>mouse      </td><td>0.8881707  </td><td>first      </td><td>mw         </td><td>-0.25490082</td><td>0.11182934 </td></tr>\n",
       "\t<tr><td>5390       </td><td>mouse      </td><td>0.7804937  </td><td>second     </td><td>wm         </td><td> 0.26316639</td><td>0.21950628 </td></tr>\n",
       "\t<tr><td>5399       </td><td>mouse      </td><td>0.9342180  </td><td>second     </td><td>wm         </td><td> 0.16677408</td><td>0.06578196 </td></tr>\n",
       "\t<tr><td>5571       </td><td>mouse      </td><td>0.9786815  </td><td>first      </td><td>mw         </td><td>-0.21080130</td><td>0.02131849 </td></tr>\n",
       "\t<tr><td>5752       </td><td>mouse      </td><td>0.9467038  </td><td>second     </td><td>wm         </td><td>-0.42202924</td><td>0.05329623 </td></tr>\n",
       "\t<tr><td>5778       </td><td>mouse      </td><td>0.6649971  </td><td>first      </td><td>mw         </td><td> 0.26514515</td><td>0.33500285 </td></tr>\n",
       "\t<tr><td>5781       </td><td>mouse      </td><td>0.7926227  </td><td>first      </td><td>mw         </td><td>-0.06996582</td><td>0.20737728 </td></tr>\n",
       "\t<tr><td>5813       </td><td>mouse      </td><td>0.9062785  </td><td>first      </td><td>mw         </td><td>-0.03194883</td><td>0.09372146 </td></tr>\n",
       "\t<tr><td>5950       </td><td>mouse      </td><td>0.6792666  </td><td>second     </td><td>wm         </td><td> 0.02617145</td><td>0.32073345 </td></tr>\n",
       "\t<tr><td>5953       </td><td>mouse      </td><td>0.6494150  </td><td>first      </td><td>mw         </td><td> 0.07082642</td><td>0.35058505 </td></tr>\n",
       "\t<tr><td>5966       </td><td>mouse      </td><td>0.8042095  </td><td>first      </td><td>mw         </td><td>-0.17676952</td><td>0.19579053 </td></tr>\n",
       "\t<tr><td>5985       </td><td>mouse      </td><td>0.9861016  </td><td>second     </td><td>wm         </td><td> 0.14144531</td><td>0.01389840 </td></tr>\n",
       "\t<tr><td>6022       </td><td>mouse      </td><td>0.9475742  </td><td>second     </td><td>wm         </td><td> 0.17679910</td><td>0.05242580 </td></tr>\n",
       "\t<tr><td>6025       </td><td>mouse      </td><td>0.7591752  </td><td>second     </td><td>wm         </td><td>-0.04252966</td><td>0.24082477 </td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>5950       </td><td>walking    </td><td>0.9591324  </td><td>first      </td><td>wm         </td><td> 0.02617145</td><td>0.04086758 </td></tr>\n",
       "\t<tr><td>5953       </td><td>walking    </td><td>0.5893693  </td><td>second     </td><td>mw         </td><td> 0.07082642</td><td>0.41063071 </td></tr>\n",
       "\t<tr><td>5966       </td><td>walking    </td><td>0.6375143  </td><td>second     </td><td>mw         </td><td>-0.17676952</td><td>0.36248573 </td></tr>\n",
       "\t<tr><td>5985       </td><td>walking    </td><td>0.9753710  </td><td>first      </td><td>wm         </td><td> 0.14144531</td><td>0.02462900 </td></tr>\n",
       "\t<tr><td>6022       </td><td>walking    </td><td>0.9484304  </td><td>first      </td><td>wm         </td><td> 0.17679910</td><td>0.05156963 </td></tr>\n",
       "\t<tr><td>6025       </td><td>walking    </td><td>0.7427083  </td><td>first      </td><td>wm         </td><td>-0.04252966</td><td>0.25729167 </td></tr>\n",
       "\t<tr><td>6076       </td><td>walking    </td><td>0.5980736  </td><td>second     </td><td>mw         </td><td> 0.08004683</td><td>0.40192637 </td></tr>\n",
       "\t<tr><td>6131       </td><td>walking    </td><td>0.9761130  </td><td>second     </td><td>mw         </td><td> 0.04317653</td><td>0.02388699 </td></tr>\n",
       "\t<tr><td>6147       </td><td>walking    </td><td>0.9031963  </td><td>first      </td><td>wm         </td><td> 0.19564622</td><td>0.09680365 </td></tr>\n",
       "\t<tr><td>6179       </td><td>walking    </td><td>0.3469035  </td><td>first      </td><td>wm         </td><td> 0.22635317</td><td>0.65309646 </td></tr>\n",
       "\t<tr><td>6306       </td><td>walking    </td><td>0.9718322  </td><td>second     </td><td>mw         </td><td>-0.38401389</td><td>0.02816781 </td></tr>\n",
       "\t<tr><td>6343       </td><td>walking    </td><td>0.7535245  </td><td>second     </td><td>mw         </td><td> 0.19602347</td><td>0.24647546 </td></tr>\n",
       "\t<tr><td>6573       </td><td>walking    </td><td>0.5227026  </td><td>first      </td><td>wm         </td><td> 0.33148564</td><td>0.47729737 </td></tr>\n",
       "\t<tr><td>6688       </td><td>walking    </td><td>0.9142837  </td><td>first      </td><td>wm         </td><td>-0.21838181</td><td>0.08571632 </td></tr>\n",
       "\t<tr><td>6703       </td><td>walking    </td><td>0.9085331  </td><td>second     </td><td>mw         </td><td>-0.27438561</td><td>0.09146689 </td></tr>\n",
       "\t<tr><td>6920       </td><td>walking    </td><td>0.7518122  </td><td>first      </td><td>wm         </td><td> 0.04678437</td><td>0.24818779 </td></tr>\n",
       "\t<tr><td>7331       </td><td>walking    </td><td>0.7256707  </td><td>second     </td><td>mw         </td><td>-0.12043847</td><td>0.27432934 </td></tr>\n",
       "\t<tr><td>7500       </td><td>walking    </td><td>0.9035816  </td><td>first      </td><td>wm         </td><td> 0.11489750</td><td>0.09641838 </td></tr>\n",
       "\t<tr><td>7502       </td><td>walking    </td><td>0.6794663  </td><td>second     </td><td>mw         </td><td>-0.11267438</td><td>0.32053368 </td></tr>\n",
       "\t<tr><td>7921       </td><td>walking    </td><td>0.9762272  </td><td>first      </td><td>wm         </td><td>-0.12309848</td><td>0.02377283 </td></tr>\n",
       "\t<tr><td>7993       </td><td>walking    </td><td>0.9216039  </td><td>first      </td><td>wm         </td><td> 0.03532073</td><td>0.07839612 </td></tr>\n",
       "\t<tr><td>7998       </td><td>walking    </td><td>0.7106307  </td><td>second     </td><td>mw         </td><td>-0.13579801</td><td>0.28936929 </td></tr>\n",
       "\t<tr><td>8044       </td><td>walking    </td><td>0.7401684  </td><td>first      </td><td>wm         </td><td>-0.20868007</td><td>0.25983162 </td></tr>\n",
       "\t<tr><td>8946       </td><td>walking    </td><td>0.6488442  </td><td>second     </td><td>mw         </td><td>-0.12068300</td><td>0.35115582 </td></tr>\n",
       "\t<tr><td>9155       </td><td>walking    </td><td>0.9467180  </td><td>first      </td><td>wm         </td><td> 0.07843856</td><td>0.05328196 </td></tr>\n",
       "\t<tr><td>9709       </td><td>walking    </td><td>0.4428796  </td><td>second     </td><td>mw         </td><td>-0.01261043</td><td>0.55712043 </td></tr>\n",
       "\t<tr><td>9711       </td><td>walking    </td><td>0.3350885  </td><td>second     </td><td>mw         </td><td> 0.02141986</td><td>0.66491153 </td></tr>\n",
       "\t<tr><td>9792       </td><td>walking    </td><td>0.6736159  </td><td>first      </td><td>wm         </td><td> 0.20292245</td><td>0.32638413 </td></tr>\n",
       "\t<tr><td>9864       </td><td>walking    </td><td>0.8638556  </td><td>first      </td><td>wm         </td><td>-0.35916693</td><td>0.13614441 </td></tr>\n",
       "\t<tr><td>9970       </td><td>walking    </td><td>0.8108019  </td><td>first      </td><td>wm         </td><td> 0.15647734</td><td>0.18919806 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " subj\\_id & task & k & session & sequence & SS\\_bias & AUC\\\\\n",
       "\\hline\n",
       "\t 1322        & mouse       & 0.9325057   & first       & mw          & -0.48821750 & 0.06749429 \\\\\n",
       "\t 1402        & mouse       & 0.9703482   & first       & mw          &  0.03046794 & 0.02965183 \\\\\n",
       "\t 1408        & mouse       & 0.3983733   & second      & wm          &  0.11081885 & 0.60162671 \\\\\n",
       "\t 1474        & mouse       & 0.8751284   & first       & mw          & -0.04696042 & 0.12487158 \\\\\n",
       "\t 1879        & mouse       & 0.8239869   & second      & wm          & -0.27269836 & 0.17601313 \\\\\n",
       "\t 2045        & mouse       & 0.7232734   & first       & mw          & -0.50074000 & 0.27672660 \\\\\n",
       "\t 2249        & mouse       & 0.9584760   & first       & mw          & -0.60422898 & 0.04152397 \\\\\n",
       "\t 2261        & mouse       & 0.8941924   & first       & mw          & -0.57138308 & 0.10580765 \\\\\n",
       "\t 2752        & mouse       & 0.9527112   & second      & wm          &  0.14741077 & 0.04728881 \\\\\n",
       "\t 2758        & mouse       & 0.8964184   & second      & wm          & -0.17682609 & 0.10358162 \\\\\n",
       "\t 3713        & mouse       & 0.9201627   & first       & mw          & -0.24616666 & 0.07983733 \\\\\n",
       "\t 3720        & mouse       & 0.9576056   & first       & mw          & -0.11799166 & 0.04239441 \\\\\n",
       "\t 4037        & mouse       & 0.2347175   & second      & wm          & -0.17281631 & 0.76528253 \\\\\n",
       "\t 4413        & mouse       & 0.8990725   & first       & mw          &  0.10286513 & 0.10092751 \\\\\n",
       "\t 4422        & mouse       & 0.9084047   & first       & mw          & -0.16070781 & 0.09159532 \\\\\n",
       "\t 4441        & mouse       & 0.8923516   & second      & wm          &  0.14034046 & 0.10764840 \\\\\n",
       "\t 5181        & mouse       & 0.8881707   & first       & mw          & -0.25490082 & 0.11182934 \\\\\n",
       "\t 5390        & mouse       & 0.7804937   & second      & wm          &  0.26316639 & 0.21950628 \\\\\n",
       "\t 5399        & mouse       & 0.9342180   & second      & wm          &  0.16677408 & 0.06578196 \\\\\n",
       "\t 5571        & mouse       & 0.9786815   & first       & mw          & -0.21080130 & 0.02131849 \\\\\n",
       "\t 5752        & mouse       & 0.9467038   & second      & wm          & -0.42202924 & 0.05329623 \\\\\n",
       "\t 5778        & mouse       & 0.6649971   & first       & mw          &  0.26514515 & 0.33500285 \\\\\n",
       "\t 5781        & mouse       & 0.7926227   & first       & mw          & -0.06996582 & 0.20737728 \\\\\n",
       "\t 5813        & mouse       & 0.9062785   & first       & mw          & -0.03194883 & 0.09372146 \\\\\n",
       "\t 5950        & mouse       & 0.6792666   & second      & wm          &  0.02617145 & 0.32073345 \\\\\n",
       "\t 5953        & mouse       & 0.6494150   & first       & mw          &  0.07082642 & 0.35058505 \\\\\n",
       "\t 5966        & mouse       & 0.8042095   & first       & mw          & -0.17676952 & 0.19579053 \\\\\n",
       "\t 5985        & mouse       & 0.9861016   & second      & wm          &  0.14144531 & 0.01389840 \\\\\n",
       "\t 6022        & mouse       & 0.9475742   & second      & wm          &  0.17679910 & 0.05242580 \\\\\n",
       "\t 6025        & mouse       & 0.7591752   & second      & wm          & -0.04252966 & 0.24082477 \\\\\n",
       "\t ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t 5950        & walking     & 0.9591324   & first       & wm          &  0.02617145 & 0.04086758 \\\\\n",
       "\t 5953        & walking     & 0.5893693   & second      & mw          &  0.07082642 & 0.41063071 \\\\\n",
       "\t 5966        & walking     & 0.6375143   & second      & mw          & -0.17676952 & 0.36248573 \\\\\n",
       "\t 5985        & walking     & 0.9753710   & first       & wm          &  0.14144531 & 0.02462900 \\\\\n",
       "\t 6022        & walking     & 0.9484304   & first       & wm          &  0.17679910 & 0.05156963 \\\\\n",
       "\t 6025        & walking     & 0.7427083   & first       & wm          & -0.04252966 & 0.25729167 \\\\\n",
       "\t 6076        & walking     & 0.5980736   & second      & mw          &  0.08004683 & 0.40192637 \\\\\n",
       "\t 6131        & walking     & 0.9761130   & second      & mw          &  0.04317653 & 0.02388699 \\\\\n",
       "\t 6147        & walking     & 0.9031963   & first       & wm          &  0.19564622 & 0.09680365 \\\\\n",
       "\t 6179        & walking     & 0.3469035   & first       & wm          &  0.22635317 & 0.65309646 \\\\\n",
       "\t 6306        & walking     & 0.9718322   & second      & mw          & -0.38401389 & 0.02816781 \\\\\n",
       "\t 6343        & walking     & 0.7535245   & second      & mw          &  0.19602347 & 0.24647546 \\\\\n",
       "\t 6573        & walking     & 0.5227026   & first       & wm          &  0.33148564 & 0.47729737 \\\\\n",
       "\t 6688        & walking     & 0.9142837   & first       & wm          & -0.21838181 & 0.08571632 \\\\\n",
       "\t 6703        & walking     & 0.9085331   & second      & mw          & -0.27438561 & 0.09146689 \\\\\n",
       "\t 6920        & walking     & 0.7518122   & first       & wm          &  0.04678437 & 0.24818779 \\\\\n",
       "\t 7331        & walking     & 0.7256707   & second      & mw          & -0.12043847 & 0.27432934 \\\\\n",
       "\t 7500        & walking     & 0.9035816   & first       & wm          &  0.11489750 & 0.09641838 \\\\\n",
       "\t 7502        & walking     & 0.6794663   & second      & mw          & -0.11267438 & 0.32053368 \\\\\n",
       "\t 7921        & walking     & 0.9762272   & first       & wm          & -0.12309848 & 0.02377283 \\\\\n",
       "\t 7993        & walking     & 0.9216039   & first       & wm          &  0.03532073 & 0.07839612 \\\\\n",
       "\t 7998        & walking     & 0.7106307   & second      & mw          & -0.13579801 & 0.28936929 \\\\\n",
       "\t 8044        & walking     & 0.7401684   & first       & wm          & -0.20868007 & 0.25983162 \\\\\n",
       "\t 8946        & walking     & 0.6488442   & second      & mw          & -0.12068300 & 0.35115582 \\\\\n",
       "\t 9155        & walking     & 0.9467180   & first       & wm          &  0.07843856 & 0.05328196 \\\\\n",
       "\t 9709        & walking     & 0.4428796   & second      & mw          & -0.01261043 & 0.55712043 \\\\\n",
       "\t 9711        & walking     & 0.3350885   & second      & mw          &  0.02141986 & 0.66491153 \\\\\n",
       "\t 9792        & walking     & 0.6736159   & first       & wm          &  0.20292245 & 0.32638413 \\\\\n",
       "\t 9864        & walking     & 0.8638556   & first       & wm          & -0.35916693 & 0.13614441 \\\\\n",
       "\t 9970        & walking     & 0.8108019   & first       & wm          &  0.15647734 & 0.18919806 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "subj_id | task | k | session | sequence | SS_bias | AUC | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1322        | mouse       | 0.9325057   | first       | mw          | -0.48821750 | 0.06749429  | \n",
       "| 1402        | mouse       | 0.9703482   | first       | mw          |  0.03046794 | 0.02965183  | \n",
       "| 1408        | mouse       | 0.3983733   | second      | wm          |  0.11081885 | 0.60162671  | \n",
       "| 1474        | mouse       | 0.8751284   | first       | mw          | -0.04696042 | 0.12487158  | \n",
       "| 1879        | mouse       | 0.8239869   | second      | wm          | -0.27269836 | 0.17601313  | \n",
       "| 2045        | mouse       | 0.7232734   | first       | mw          | -0.50074000 | 0.27672660  | \n",
       "| 2249        | mouse       | 0.9584760   | first       | mw          | -0.60422898 | 0.04152397  | \n",
       "| 2261        | mouse       | 0.8941924   | first       | mw          | -0.57138308 | 0.10580765  | \n",
       "| 2752        | mouse       | 0.9527112   | second      | wm          |  0.14741077 | 0.04728881  | \n",
       "| 2758        | mouse       | 0.8964184   | second      | wm          | -0.17682609 | 0.10358162  | \n",
       "| 3713        | mouse       | 0.9201627   | first       | mw          | -0.24616666 | 0.07983733  | \n",
       "| 3720        | mouse       | 0.9576056   | first       | mw          | -0.11799166 | 0.04239441  | \n",
       "| 4037        | mouse       | 0.2347175   | second      | wm          | -0.17281631 | 0.76528253  | \n",
       "| 4413        | mouse       | 0.8990725   | first       | mw          |  0.10286513 | 0.10092751  | \n",
       "| 4422        | mouse       | 0.9084047   | first       | mw          | -0.16070781 | 0.09159532  | \n",
       "| 4441        | mouse       | 0.8923516   | second      | wm          |  0.14034046 | 0.10764840  | \n",
       "| 5181        | mouse       | 0.8881707   | first       | mw          | -0.25490082 | 0.11182934  | \n",
       "| 5390        | mouse       | 0.7804937   | second      | wm          |  0.26316639 | 0.21950628  | \n",
       "| 5399        | mouse       | 0.9342180   | second      | wm          |  0.16677408 | 0.06578196  | \n",
       "| 5571        | mouse       | 0.9786815   | first       | mw          | -0.21080130 | 0.02131849  | \n",
       "| 5752        | mouse       | 0.9467038   | second      | wm          | -0.42202924 | 0.05329623  | \n",
       "| 5778        | mouse       | 0.6649971   | first       | mw          |  0.26514515 | 0.33500285  | \n",
       "| 5781        | mouse       | 0.7926227   | first       | mw          | -0.06996582 | 0.20737728  | \n",
       "| 5813        | mouse       | 0.9062785   | first       | mw          | -0.03194883 | 0.09372146  | \n",
       "| 5950        | mouse       | 0.6792666   | second      | wm          |  0.02617145 | 0.32073345  | \n",
       "| 5953        | mouse       | 0.6494150   | first       | mw          |  0.07082642 | 0.35058505  | \n",
       "| 5966        | mouse       | 0.8042095   | first       | mw          | -0.17676952 | 0.19579053  | \n",
       "| 5985        | mouse       | 0.9861016   | second      | wm          |  0.14144531 | 0.01389840  | \n",
       "| 6022        | mouse       | 0.9475742   | second      | wm          |  0.17679910 | 0.05242580  | \n",
       "| 6025        | mouse       | 0.7591752   | second      | wm          | -0.04252966 | 0.24082477  | \n",
       "| ... | ... | ... | ... | ... | ... | ... | \n",
       "| 5950        | walking     | 0.9591324   | first       | wm          |  0.02617145 | 0.04086758  | \n",
       "| 5953        | walking     | 0.5893693   | second      | mw          |  0.07082642 | 0.41063071  | \n",
       "| 5966        | walking     | 0.6375143   | second      | mw          | -0.17676952 | 0.36248573  | \n",
       "| 5985        | walking     | 0.9753710   | first       | wm          |  0.14144531 | 0.02462900  | \n",
       "| 6022        | walking     | 0.9484304   | first       | wm          |  0.17679910 | 0.05156963  | \n",
       "| 6025        | walking     | 0.7427083   | first       | wm          | -0.04252966 | 0.25729167  | \n",
       "| 6076        | walking     | 0.5980736   | second      | mw          |  0.08004683 | 0.40192637  | \n",
       "| 6131        | walking     | 0.9761130   | second      | mw          |  0.04317653 | 0.02388699  | \n",
       "| 6147        | walking     | 0.9031963   | first       | wm          |  0.19564622 | 0.09680365  | \n",
       "| 6179        | walking     | 0.3469035   | first       | wm          |  0.22635317 | 0.65309646  | \n",
       "| 6306        | walking     | 0.9718322   | second      | mw          | -0.38401389 | 0.02816781  | \n",
       "| 6343        | walking     | 0.7535245   | second      | mw          |  0.19602347 | 0.24647546  | \n",
       "| 6573        | walking     | 0.5227026   | first       | wm          |  0.33148564 | 0.47729737  | \n",
       "| 6688        | walking     | 0.9142837   | first       | wm          | -0.21838181 | 0.08571632  | \n",
       "| 6703        | walking     | 0.9085331   | second      | mw          | -0.27438561 | 0.09146689  | \n",
       "| 6920        | walking     | 0.7518122   | first       | wm          |  0.04678437 | 0.24818779  | \n",
       "| 7331        | walking     | 0.7256707   | second      | mw          | -0.12043847 | 0.27432934  | \n",
       "| 7500        | walking     | 0.9035816   | first       | wm          |  0.11489750 | 0.09641838  | \n",
       "| 7502        | walking     | 0.6794663   | second      | mw          | -0.11267438 | 0.32053368  | \n",
       "| 7921        | walking     | 0.9762272   | first       | wm          | -0.12309848 | 0.02377283  | \n",
       "| 7993        | walking     | 0.9216039   | first       | wm          |  0.03532073 | 0.07839612  | \n",
       "| 7998        | walking     | 0.7106307   | second      | mw          | -0.13579801 | 0.28936929  | \n",
       "| 8044        | walking     | 0.7401684   | first       | wm          | -0.20868007 | 0.25983162  | \n",
       "| 8946        | walking     | 0.6488442   | second      | mw          | -0.12068300 | 0.35115582  | \n",
       "| 9155        | walking     | 0.9467180   | first       | wm          |  0.07843856 | 0.05328196  | \n",
       "| 9709        | walking     | 0.4428796   | second      | mw          | -0.01261043 | 0.55712043  | \n",
       "| 9711        | walking     | 0.3350885   | second      | mw          |  0.02141986 | 0.66491153  | \n",
       "| 9792        | walking     | 0.6736159   | first       | wm          |  0.20292245 | 0.32638413  | \n",
       "| 9864        | walking     | 0.8638556   | first       | wm          | -0.35916693 | 0.13614441  | \n",
       "| 9970        | walking     | 0.8108019   | first       | wm          |  0.15647734 | 0.18919806  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    subj_id task    k         session sequence SS_bias     AUC       \n",
       "1   1322    mouse   0.9325057 first   mw       -0.48821750 0.06749429\n",
       "2   1402    mouse   0.9703482 first   mw        0.03046794 0.02965183\n",
       "3   1408    mouse   0.3983733 second  wm        0.11081885 0.60162671\n",
       "4   1474    mouse   0.8751284 first   mw       -0.04696042 0.12487158\n",
       "5   1879    mouse   0.8239869 second  wm       -0.27269836 0.17601313\n",
       "6   2045    mouse   0.7232734 first   mw       -0.50074000 0.27672660\n",
       "7   2249    mouse   0.9584760 first   mw       -0.60422898 0.04152397\n",
       "8   2261    mouse   0.8941924 first   mw       -0.57138308 0.10580765\n",
       "9   2752    mouse   0.9527112 second  wm        0.14741077 0.04728881\n",
       "10  2758    mouse   0.8964184 second  wm       -0.17682609 0.10358162\n",
       "11  3713    mouse   0.9201627 first   mw       -0.24616666 0.07983733\n",
       "12  3720    mouse   0.9576056 first   mw       -0.11799166 0.04239441\n",
       "13  4037    mouse   0.2347175 second  wm       -0.17281631 0.76528253\n",
       "14  4413    mouse   0.8990725 first   mw        0.10286513 0.10092751\n",
       "15  4422    mouse   0.9084047 first   mw       -0.16070781 0.09159532\n",
       "16  4441    mouse   0.8923516 second  wm        0.14034046 0.10764840\n",
       "17  5181    mouse   0.8881707 first   mw       -0.25490082 0.11182934\n",
       "18  5390    mouse   0.7804937 second  wm        0.26316639 0.21950628\n",
       "19  5399    mouse   0.9342180 second  wm        0.16677408 0.06578196\n",
       "20  5571    mouse   0.9786815 first   mw       -0.21080130 0.02131849\n",
       "21  5752    mouse   0.9467038 second  wm       -0.42202924 0.05329623\n",
       "22  5778    mouse   0.6649971 first   mw        0.26514515 0.33500285\n",
       "23  5781    mouse   0.7926227 first   mw       -0.06996582 0.20737728\n",
       "24  5813    mouse   0.9062785 first   mw       -0.03194883 0.09372146\n",
       "25  5950    mouse   0.6792666 second  wm        0.02617145 0.32073345\n",
       "26  5953    mouse   0.6494150 first   mw        0.07082642 0.35058505\n",
       "27  5966    mouse   0.8042095 first   mw       -0.17676952 0.19579053\n",
       "28  5985    mouse   0.9861016 second  wm        0.14144531 0.01389840\n",
       "29  6022    mouse   0.9475742 second  wm        0.17679910 0.05242580\n",
       "30  6025    mouse   0.7591752 second  wm       -0.04252966 0.24082477\n",
       "... ...     ...     ...       ...     ...      ...         ...       \n",
       "79  5950    walking 0.9591324 first   wm        0.02617145 0.04086758\n",
       "80  5953    walking 0.5893693 second  mw        0.07082642 0.41063071\n",
       "81  5966    walking 0.6375143 second  mw       -0.17676952 0.36248573\n",
       "82  5985    walking 0.9753710 first   wm        0.14144531 0.02462900\n",
       "83  6022    walking 0.9484304 first   wm        0.17679910 0.05156963\n",
       "84  6025    walking 0.7427083 first   wm       -0.04252966 0.25729167\n",
       "85  6076    walking 0.5980736 second  mw        0.08004683 0.40192637\n",
       "86  6131    walking 0.9761130 second  mw        0.04317653 0.02388699\n",
       "87  6147    walking 0.9031963 first   wm        0.19564622 0.09680365\n",
       "88  6179    walking 0.3469035 first   wm        0.22635317 0.65309646\n",
       "89  6306    walking 0.9718322 second  mw       -0.38401389 0.02816781\n",
       "90  6343    walking 0.7535245 second  mw        0.19602347 0.24647546\n",
       "91  6573    walking 0.5227026 first   wm        0.33148564 0.47729737\n",
       "92  6688    walking 0.9142837 first   wm       -0.21838181 0.08571632\n",
       "93  6703    walking 0.9085331 second  mw       -0.27438561 0.09146689\n",
       "94  6920    walking 0.7518122 first   wm        0.04678437 0.24818779\n",
       "95  7331    walking 0.7256707 second  mw       -0.12043847 0.27432934\n",
       "96  7500    walking 0.9035816 first   wm        0.11489750 0.09641838\n",
       "97  7502    walking 0.6794663 second  mw       -0.11267438 0.32053368\n",
       "98  7921    walking 0.9762272 first   wm       -0.12309848 0.02377283\n",
       "99  7993    walking 0.9216039 first   wm        0.03532073 0.07839612\n",
       "100 7998    walking 0.7106307 second  mw       -0.13579801 0.28936929\n",
       "101 8044    walking 0.7401684 first   wm       -0.20868007 0.25983162\n",
       "102 8946    walking 0.6488442 second  mw       -0.12068300 0.35115582\n",
       "103 9155    walking 0.9467180 first   wm        0.07843856 0.05328196\n",
       "104 9709    walking 0.4428796 second  mw       -0.01261043 0.55712043\n",
       "105 9711    walking 0.3350885 second  mw        0.02141986 0.66491153\n",
       "106 9792    walking 0.6736159 first   wm        0.20292245 0.32638413\n",
       "107 9864    walking 0.8638556 first   wm       -0.35916693 0.13614441\n",
       "108 9970    walking 0.8108019 first   wm        0.15647734 0.18919806"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to what was assumed at the time of preregistration, k-values aren't approximated well by the normal distribution. Still, we check Bayes factors according to the originally specified design (`gaussian` family parameter in brms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\nXZJHAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"Histogram and theoretical densities\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit_w  <- fitdist(data$k, \"norm\")\n",
    "denscomp(fit_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.329 seconds (Warm-up)\n",
      "               0.134 seconds (Sampling)\n",
      "               0.463 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.325 seconds (Warm-up)\n",
      "               0.136 seconds (Sampling)\n",
      "               0.461 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.343 seconds (Warm-up)\n",
      "               0.13 seconds (Sampling)\n",
      "               0.473 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.347 seconds (Warm-up)\n",
      "               0.171 seconds (Sampling)\n",
      "               0.518 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.366 seconds (Warm-up)\n",
      "               0.17 seconds (Sampling)\n",
      "               0.536 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.396 seconds (Warm-up)\n",
      "               0.164 seconds (Sampling)\n",
      "               0.56 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.387 seconds (Warm-up)\n",
      "               0.172 seconds (Sampling)\n",
      "               0.559 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.385 seconds (Warm-up)\n",
      "               0.164 seconds (Sampling)\n",
      "               0.549 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.414 seconds (Warm-up)\n",
      "               0.221 seconds (Sampling)\n",
      "               0.635 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.431 seconds (Warm-up)\n",
      "               0.174 seconds (Sampling)\n",
      "               0.605 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.432 seconds (Warm-up)\n",
      "               0.193 seconds (Sampling)\n",
      "               0.625 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.39 seconds (Warm-up)\n",
      "               0.174 seconds (Sampling)\n",
      "               0.564 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n"
     ]
    }
   ],
   "source": [
    "prereg_result <- get_bf_k(data, 'k', gaussian(), 0.707, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(prereg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(marginal_effects(prereg_result$m_task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_posterior(prereg_result$m_task, file_name = sprintf(\"posterior_%s_%s.%s\", \"k_task\", \"prereg\", \"csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accounting for the observed distribution of $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reaching BF>10 in favor of null model over the model with the main effect of task, we terminated data collection, even though BF of the model with the session effect has not yet reached the designated boundary of 10. The reason was that it became evident that there is no difference in discounting behavior between tasks.  Just in case, we checked that this holds if we change the `family` parameter of the brms regression to `weibull`, as Weibull distribution more closely matches the distribution of k-values (we ran the model on zero-peaked quantity `1-k`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_w  <- fitdist(data$AUC, \"weibull\")\n",
    "denscomp(fit_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AUC_weibull_result <- get_bf_k(data, 'AUC', weibull(), 0.707, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(AUC_weibull_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes factors in favor of the null model decreased and became less conclusive. We however think that using a modified definition of k-value can help to further clarify whether the task or session afffected k. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using log-delays in calculating k-values\n",
    "\n",
    "Specifically, as many subjects are close to the head part of the k-value distribution (0.9 to 1.0), we might want to emphasize small differences in discounting curves for these subjects. We can do this by changing the definition of k-value in line with Killeen's additive utility model of delay discounting. Specifically, we use log-scaled delays when calculating k-values (which are recorded to \\_log.csv files during preprocessing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_delay_data <- get_data(data_path, \"k_values_54_log.csv\")\n",
    "print(nrow(log_delay_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These k-values are more normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_w  <- fitdist(log_delay_data$k, \"norm\")\n",
    "denscomp(fit_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_delay_result <- get_bf_k(log_delay_data, 'k', gaussian(), 0.707, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_result(log_delay_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bf_table <- function(prereg_result, AUC_weibull_result, log_delay_result, caption, label, file_name){\n",
    "    hyp_2_format_string <- \"\\\\begin{table}[]\n",
    "                \\\\centering\n",
    "                \\\\sisetup{round-mode=places, round-precision=1, scientific-notation=false}\n",
    "                \\\\caption{%s}\n",
    "                \\\\label{%s}\n",
    "                \\\\begin{tabular}{@{}lll@{}}\n",
    "                \\\\toprule\n",
    "                dependent variable & $\\\\textrm{M}_{\\\\textrm{task}}$ & $\\\\textrm{M}_{\\\\textrm{session}}$ \\\\\\\\ \\\\midrule\n",
    "                $k \\\\sim ~ \\\\textrm{Gaussian}$ & 1/\\\\num{%g} & 1/\\\\num{%g}  \\\\\\\\\n",
    "                $k \\\\sim ~ \\\\textrm{Weibull}$ & 1/\\\\num{%g} & 1/\\\\num{%g}  \\\\\\\\\n",
    "                $k_{\\\\log} \\\\sim ~ \\\\textrm{Gaussian}$ & 1/\\\\num{%g} & \\\\num{%g}\\\\\\\\ \\\\bottomrule\n",
    "                \\\\end{tabular}\n",
    "                \\\\end{table}\"\n",
    "    \n",
    "    output <- sprintf(hyp_2_format_string, caption, label, \n",
    "                      1/prereg_result$bf[1], 1/prereg_result$bf[2], \n",
    "                      1/AUC_weibull_result$bf[1], 1/AUC_weibull_result$bf[2], \n",
    "                      1/log_delay_result$bf[1], log_delay_result$bf[2])\n",
    "\n",
    "    fileConn<-file(file.path(table_path, file_name))\n",
    "    writeLines(output, fileConn)\n",
    "    close(fileConn)    \n",
    "}\n",
    "\n",
    "caption = \"Results of testing Hypothesis 2: Bayes factors of the task-only and session-only models \n",
    "        over the null model produced by the preregistered analysis ($k \\\\sim ~ \\\\textrm{Gaussian}$) and \n",
    "        two exploratory analyses\"\n",
    "label = \"tab:hyp_2_bf\"\n",
    "file_name = \"hyp_2_bf.tex\"\n",
    "\n",
    "save_bf_table(prereg_result, AUC_weibull_result, log_delay_result, caption, label, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the effect of rscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_results <- function(rscale){\n",
    "    prereg_result <- get_bf_k(data, 'k', gaussian(), rscale)\n",
    "    AUC_Weibull_result <- get_bf_k(data, 'k', weibull(), rscale)\n",
    "    log_delay_result <- get_bf_k(log_delay_data, 'k', gaussian(), rscale)\n",
    "    \n",
    "    result = list(prereg_result=prereg_result,  \n",
    "                  AUC_Weibull_result=AUC_Weibull_result, \n",
    "                  log_delay_result=log_delay_result)\n",
    "    \n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrower priors (rscale = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_prior_results <- get_all_results(rscale = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(narrow_prior_results$prereg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(narrow_prior_results$AUC_Weibull_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(narrow_prior_results$log_delay_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wider priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_prior_results <- get_all_results(rscale = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(wide_prior_results$prereg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(wide_prior_results$AUC_Weibull_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(wide_prior_results$log_delay_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving everything to RData file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save.image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
