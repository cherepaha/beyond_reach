{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "Loading 'brms' package (version 2.4.0). Useful instructions\n",
      "can be found by typing help('brms'). A more detailed introduction\n",
      "to the package is available through vignette('brms_overview').\n",
      "Run theme_set(theme_default()) to use the default bayesplot theme.\n",
      "NOTE: As of tidybayes version 1.0, several functions, arguments, and output column names\n",
      "      have undergone significant name changes in order to adopt a unified naming scheme.\n",
      "      See help('tidybayes-deprecated') for more information.\n",
      "\n",
      "\n",
      "Attaching package: 'ggstance'\n",
      "\n",
      "The following objects are masked from 'package:ggplot2':\n",
      "\n",
      "    geom_errorbarh, GeomErrorbarh\n",
      "\n",
      "Loading required package: viridisLite\n",
      "\n",
      "Attaching package: 'data.table'\n",
      "\n",
      "The following objects are masked from 'package:reshape2':\n",
      "\n",
      "    dcast, melt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "library(ggExtra)\n",
    "library(brms)\n",
    "library(reshape2)\n",
    "library(coda)\n",
    "library(tidybayes)\n",
    "library(ggstance)\n",
    "library(viridis)\n",
    "library(latex2exp)\n",
    "library(ggthemes)\n",
    "library(data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "102"
      ],
      "text/latex": [
       "102"
      ],
      "text/markdown": [
       "102"
      ],
      "text/plain": [
       "[1] 102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_data <- function(){\n",
    "    filename <- \"C:/Users/Arkady/Google Drive/data/beyond_the_reach/k-values.txt\"\n",
    "    data <- read.table(filename, header = TRUE, sep = \"\\t\")\n",
    "    data[, 'subj_id'] <- factor(data[, 'subj_id'])  \n",
    "    data[, 'task'] <- factor(data[, 'task'])  \n",
    "    data[, 'order'] <- factor(data[, 'order'])  \n",
    "    return(data)\n",
    "}\n",
    "\n",
    "data <- get_data()\n",
    "nrow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bf_k <- function(data){\n",
    "    # sd(IV) in this case is 0.5, as IV is task (equal number of 0's and 1's)\n",
    "    priors_task <- c(set_prior(sprintf('normal(%f, %f)', mean(data$k), sd(data$k)), class = 'Intercept'),\n",
    "                    set_prior(sprintf('cauchy(0.0, %f)', 0.707*sd(data$k)/0.5), class = 'b'))\n",
    "\n",
    "    m_null <- brm(k ~ (1 | subj_id), data=data, family=gaussian(), save_all_pars=TRUE, prior=priors_task[1,],\n",
    "                  refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "    m_task <- brm(k ~ (1 | subj_id) + task, data=data, family=gaussian(), save_all_pars=TRUE, prior=priors_task, \n",
    "                  refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))    \n",
    "    m_order <- brm(k ~ (1 | subj_id) + order, data=data, family=gaussian(), save_all_pars=TRUE, prior=priors_task, \n",
    "                  refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "#     m_inter <- brm(k ~ (1 | subj_id) + task*order, data=data, family=gaussian(), save_all_pars=TRUE, prior=priors_task, \n",
    "#                   refresh=0, control = list(adapt_delta = 0.9, max_treedepth=15))\n",
    "    \n",
    "    bf_task <- bayes_factor(x1=m_task, x2=m_null)$bf\n",
    "    bf_order <- bayes_factor(x1=m_order, x2=m_null)$bf\n",
    "#     bf_inter <- bayes_factor(x1=m_inter, x2=m_null)$bf\n",
    "    names(bf_task) <- 'bf_task'\n",
    "    names(bf_order) <- 'bf_order'\n",
    "#     names(bf_inter) <- 'bf_inter'\n",
    "        \n",
    "    result = list(bf=t(c(bf_task, bf_order)), m_null=m_null, m_task=m_task, m_order=m_order)\n",
    "    \n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.401 seconds (Warm-up)\n",
      "               0.167 seconds (Sampling)\n",
      "               0.568 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.405 seconds (Warm-up)\n",
      "               0.16 seconds (Sampling)\n",
      "               0.565 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.365 seconds (Warm-up)\n",
      "               0.161 seconds (Sampling)\n",
      "               0.526 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.465 seconds (Warm-up)\n",
      "               0.169 seconds (Sampling)\n",
      "               0.634 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.519 seconds (Warm-up)\n",
      "               0.241 seconds (Sampling)\n",
      "               0.76 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.532 seconds (Warm-up)\n",
      "               0.23 seconds (Sampling)\n",
      "               0.762 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.583 seconds (Warm-up)\n",
      "               0.227 seconds (Sampling)\n",
      "               0.81 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.553 seconds (Warm-up)\n",
      "               0.215 seconds (Sampling)\n",
      "               0.768 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the C++ model\n",
      "Start sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.754 seconds (Warm-up)\n",
      "               0.258 seconds (Sampling)\n",
      "               1.012 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.551 seconds (Warm-up)\n",
      "               0.252 seconds (Sampling)\n",
      "               0.803 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.66 seconds (Warm-up)\n",
      "               0.304 seconds (Sampling)\n",
      "               0.964 seconds (Total)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      " Elapsed Time: 0.57 seconds (Warm-up)\n",
      "               0.232 seconds (Sampling)\n",
      "               0.802 seconds (Total)\n",
      "\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n"
     ]
    }
   ],
   "source": [
    "result <- get_bf_k(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>bf_task</th><th scope=col>bf_order</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>14.66627</td><td>5.074242</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " bf\\_task & bf\\_order\\\\\n",
       "\\hline\n",
       "\t 14.66627 & 5.074242\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "bf_task | bf_order | \n",
       "|---|\n",
       "| 14.66627 | 5.074242 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     bf_task  bf_order\n",
       "[1,] 14.66627 5.074242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1/result$bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd_task<-HPDinterval(as.mcmc(result$m_task, combine_chains = TRUE))\n",
    "hpd_order<-HPDinterval(as.mcmc(result$m_order, combine_chains = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>lower</dt>\n",
       "\t\t<dd>-0.133042993060613</dd>\n",
       "\t<dt>upper</dt>\n",
       "\t\t<dd>0.0751451051913853</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[lower] -0.133042993060613\n",
       "\\item[upper] 0.0751451051913853\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "lower\n",
       ":   -0.133042993060613upper\n",
       ":   0.0751451051913853\n",
       "\n"
      ],
      "text/plain": [
       "      lower       upper \n",
       "-0.13304299  0.07514511 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>lower</dt>\n",
       "\t\t<dd>-0.04776541179209</dd>\n",
       "\t<dt>upper</dt>\n",
       "\t\t<dd>0.0268476318699669</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[lower] -0.04776541179209\n",
       "\\item[upper] 0.0268476318699669\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "lower\n",
       ":   -0.04776541179209upper\n",
       ":   0.0268476318699669\n",
       "\n"
      ],
      "text/plain": [
       "      lower       upper \n",
       "-0.04776541  0.02684763 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hpd_order['b_orderwm',]\n",
    "hpd_task['b_taskwalking',]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
